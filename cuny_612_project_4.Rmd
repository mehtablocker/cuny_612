---
title: "CUNY 612"
subtitle: "Project 4"
author: "mehtablocker"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

<style type="text/css">
h3 {
  color: DarkBlue;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

<br>

###Intro

__For this project we will explore the use of matrix factorization methods in the building of collaborative filtering-based recommender systems for movie ratings.__

<br>

###Load libraries

```{r load_libraries, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(recommenderlab)
library(tidytext)
library(knitr)
```

<br>

###Get data

A dataset of over 35,000 movie ratings from FilmTrust was acquired from https://www.librec.net/datasets.html and hosted on Github. We import the data frame and convert it into a User-Item matrix.

```{r load_tables}
ratings_df <- read.delim('https://raw.githubusercontent.com/mehtablocker/cuny_612/master/data_files/filmtrust/ratings.txt', header=F, sep=" ")
names(ratings_df) <- c("user_id", "item_id", "rating")
ratings_df %>% head() %>% kable()

ui_mat <- ratings_df %>% 
  arrange(user_id, item_id) %>% 
  cast_sparse(user_id, item_id, rating) %>% 
  as.matrix()
ui_mat[ui_mat==0] <- NA
ui_mat[1:5, 1:5] %>% kable()
```

<br>

###Split and normalize data

We first break the data into training and test sets, then normalize the training data by subtracting out the baseline of overall mean, user bias, and item bias.

```{r norm_data}
### Create test and train indexes
pct_test <- 0.2
n_test <- round( pct_test * sum(!is.na(ui_mat)), 0)
na_ind <- which(is.na(ui_mat))
test_ind <- sample((1:length(ui_mat))[-na_ind], n_test, replace = F)
train_ind <- (1:length(ui_mat))[-c(na_ind, test_ind)]

### Break matrix into test and train
train_mat <- ui_mat
train_mat[test_ind] <- NA
test_mat <- ui_mat
test_mat[train_ind] <- NA

### Calculate baseline and normalize matrix
global_mean <- mean(train_mat, na.rm = T)
global_mean
u_bias_vec <- unname(rowMeans(train_mat, na.rm=T)) - global_mean
u_bias_mat <- matrix(u_bias_vec, nrow=nrow(train_mat), ncol=ncol(train_mat))
i_bias_vec <- unname(colMeans(train_mat, na.rm=T)) - global_mean
i_bias_mat <- matrix(i_bias_vec, nrow=nrow(train_mat), ncol=ncol(train_mat), byrow=T)
baseline <- global_mean + u_bias_mat + i_bias_mat
train_mat_norm <- train_mat - baseline
train_mat_norm[is.na(train_mat_norm)] <- 0
```

<br>

###Build and evaluate models

We compare four different models: one built using Singular Value Decomposition, one using normalization but no matrix factorization, one using just global means, and one using Stochastic Gradient Descent (Funk SVD). The comparisons are made by calculating RMSE on the Test data.

```{r model_build}
### Perform SVD
svd_list_train <- svd(train_mat_norm)
k <- 10
u_comp <- svd_list_train$u[, 1:k]
d_comp <- svd_list_train$d[1:k]
v_comp <- svd_list_train$v[, 1:k]
train_mat_norm_comp <- u_comp %*% diag(d_comp) %*% t(v_comp)
dimnames(train_mat_norm_comp) <- dimnames(train_mat_norm)
train_mat_pred <- train_mat_norm_comp + baseline
train_mat_pred[train_mat_pred<1] <- 1
train_mat_pred[train_mat_pred>5] <- 5

### Calculate RMSE on Test data
rmse <- function(predicted, observed, rmna=FALSE){
  sqrt(mean((predicted - observed)^2, na.rm=rmna))
}

rmse_test <- rmse(train_mat_pred, test_mat, rmna=T)
rmse_test

### RMSE of simpler model (with normalization but without compression)
rmse_simpler <- rmse(train_mat_norm + baseline, test_mat, rmna=T)
rmse_simpler

### RMSE of very simple model (prediction of global average every time)
prediction_mat_chance <- matrix(mean(train_mat, na.rm=T), nrow = nrow(train_mat), ncol = ncol(train_mat))
rmse_simplest <- rmse(prediction_mat_chance, test_mat, rmna=T)
rmse_simplest

### Perform SGD (Funk SVD) and calculate RMSE on Test data
train_mat_norm <- train_mat - baseline   #can go back to keeping NA values
f_svd_list_train <- funkSVD(train_mat_norm, k = k)
train_mat_norm_comp <- f_svd_list_train$U %*% t(f_svd_list_train$V)
dimnames(train_mat_norm_comp) <- dimnames(train_mat_norm)
train_mat_pred <- train_mat_norm_comp + baseline
train_mat_pred[train_mat_pred<1] <- 1
train_mat_pred[train_mat_pred>5] <- 5
rmse_test <- rmse(train_mat_pred, test_mat, rmna=T)
rmse_test

```
