Research Discussion 4
================

## Read one or more of the articles below and consider how to counter the radicalizing effects of recommender systems or ways to prevent algorithmic discrimination.

#### Intro

In the Wired article
(<https://www.wired.com/story/creating-ethical-recommendation-engines/>)
the author touches on the question of whether free speech should be a
consideration at all in the policing of user content. I personally
believe it should. I do not think data scientists ought to generally be
in the business of trying to inflict personal morals or politics onto
users.

Having said that, I also think there are a couple caveats.

#### Considerations

First off, most of the recommender systems being discussed are the
intellectual property of private companies. I believe these companies do
have the right to bias their products towards their own morality or
political identity. I don’t think they *should*, but I think in a free
market they absolutely have the right to. Just as users have the right
to abstain from consumption.

Secondly, I think tail risk should almost always be mitigated. Even in
the wide realm of free speech there are outlier issues that need to be
managed. Things pertaining to extreme violence or inflicting great harm
upon others should fall into this category. Censorship there is
necessary, but in general this should be the exception and not the rule.
For example, there is a difference between someone encouraging mass
violence versus someone encouraging a contrarian political viewpoint.

#### Conclusion

Finally, there is the all important question of how to best curate
recommendations. The article discusses the concept of giving users more
choice and control in the recommendations made to them, and I agree. As
a user I get annoyed when continually receiving a recommendation I never
liked or wanted. The idea of having a “downgrade” button is very
appealing.
